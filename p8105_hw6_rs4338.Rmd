---
title: "p8105_hw6_rs4338"
author: "Rebecca Shyu"
date: "2024-11-20"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(haven)
library(kableExtra)
library(leaflet)
library(p8105.datasets)
library(broom)
set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
	dpi=300
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
## Problem 0:

* Create a public GitHub repo + local R Project: p8105_hw6_rs4338
* Create a single .Rmd file named p8105_hw6_rs4338.Rmd that renders to github_document
* Create a subdirectory (data) to store the local data files, and use relative paths to access these data files
* Submit a link to your repo via Courseworks: https://github.com/rysgpd/p8105_hw6_rs4338

## Problem 1:

* Plot the distribution of your estimates, and describe these in words. 
* Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r2 and log(b0 * b1)
```{r prob1_import, message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```
```{r prob1_pt1}
prob1_function1 = function(input_df) {
  input_df = as.data.frame(input_df)
  fit = lm(tmax ~ tmin, data = input_df)
  
  return(
    fit %>% 
      broom::glance() %>% 
      select(r.squared)
  )
}

prob1_results1 = 
  weather_df %>% 
  modelr::bootstrap(5000) %>% 
  mutate(
    lm_test = map(strap, prob1_function1)
  ) %>% 
  unnest(lm_test)

prob1_results1 %>% 
  ggplot(aes(x=r.squared)) + 
  geom_density() +
  labs(
    title = "Bootstrapped Samples for R^2 for Predicting Tmax using Tmin",
    x = "R Squared Values",
    y = "Density"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

``` 


* For r^2, the 95% confidence interval is `r prob1_results1 %>% pull(r.squared) %>% quantile(0.025)` to `r prob1_results1 %>% pull(r.squared) %>% quantile(0.975)`. 
* The distribution is pretty symmetrical with the r^2 values being on the higher side.

```{r prob1_pt2}

prob1_function2 = function(input_df) {
  input_df = as.data.frame(input_df)
  fit = lm(tmax ~ tmin, data = input_df)
  
  return(
    fit %>% 
      broom::tidy() %>% 
      select(term, estimate) %>% 
      pivot_wider(
        names_from = term,
        values_from = estimate) %>% 
      rename(intercept = 1)
  )
}

prob1_results2 = 
  weather_df %>% 
  modelr::bootstrap(5000) %>% 
  mutate(
    lm_test = map(strap, prob1_function2)
  ) %>% 
  unnest(lm_test) %>% 
  mutate(
    log_value = log(intercept * tmin)
  )

prob1_results2%>% 
  ggplot(aes(x=log_value)) + 
  geom_density() +
  labs(
    title = "Bootstrapped Samples for Log(B0 * B1) for Predicting Tmax using Tmin",
    x = "Log Values",
    y = "Density"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

* For the log value, the 95% confidence interval is `r prob1_results2 %>% pull(log_value) %>% quantile(0.025)` to `r prob1_results2 %>% pull(log_value) %>% quantile(0.975)`. 
* This one is less symmetrical. Bootstrapping can help get these estimates and distributions.

## Problem 2:

```{r prob2_setup}

homicide_df = read_csv("data/homicide-data.csv", na = c("", "Unknown"),
                       col_types = cols(
                         victim_sex = col_factor(levels = c("Female", "Male")),
                         victim_race = col_factor(),
                         disposition = col_factor()
                       )) %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = paste(city, state, sep = ", "),
    city_state = as.factor(city_state),
    reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"),
    solved = if_else(disposition == "Closed by arrest", 1, 0)
  ) %>% 
  filter(
    !(city_state == "Dallas, TX" | city_state == "Phoenix, AZ" | city_state == "Kansas City, MO" | city_state == "Tulsa, AL"),
    (victim_race == "White" | victim_race == "Black")
  )
```

* For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors

```{r prob2_baltimore}
balt_df = homicide_df %>% 
  filter(city_state == "Baltimore, MD")

fit = glm(solved ~ victim_age + victim_sex + victim_race, data = balt_df)

fit %>% 
  broom::tidy(conf.int=TRUE, exponentiate = TRUE) %>% 
  filter(
    term == "victim_sexMale"
  ) %>% 
  knitr::kable(caption = "Baltimore Sample Results")
```

* Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 
* Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.
  * The plot shows that there is a larger discrepancy between solved homicides when considering gender of the victim. In Albuquerque, the odds ratio is greater than 1 which means cases for male victims are about 16% more likely to be solved for male victims. In the majority of other cities, the odds ratio is less than 1, so cases for female victims in these cities are more likely to be solved. NYC is very skewed to under 0.8, which means over 20% more likely. Also, many of the confidence intervals don't even contain 1, which shows a disparity either way.


```{r prob2_function, fig.width=10}
prob2_function = function(input_df) {
  fit = glm(solved ~ victim_age + victim_sex + victim_race, data = input_df)

  return(
    fit %>% 
      broom::tidy(conf.int=TRUE, exponentiate = TRUE) %>% 
      filter(
        term == "victim_sexMale"
      ) %>% 
      select(estimate, conf.low, conf.high)
  )
}

homicide_result = 
  homicide_df %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(
    glm_tests = map(data, prob2_function)
  ) %>% 
  unnest(glm_tests) 

homicide_result %>% 
  ungroup() %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>% 
  ggplot(aes(y = city_state, x=estimate)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high))+
  labs(
    title = "Odds Ratio of Solving Homicides - Comparing Male and Female Victims",
    x = "Odds Ratio",
    y = "Location"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )


```

```{r prob3_setup}

birth_df = read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(ifelse(babysex == 1, "Male", "Female")),
    frace = as.factor(recode(frace,
                   `1` = "White",
                   `2` = "Black",
                   `3` = "Asian",
                   `4` = "Puerto Rican",
                   `8` = "Other",
                   `9` = "Unknown")),
    malform = as.factor(malform),
    mrace = as.factor(recode(mrace,
                   `1` = "White",
                   `2` = "Black",
                   `3` = "Asian",
                   `4` = "Puerto Rican",
                   `8` = "Other"))
    )

#check for missing data/general checks
# summary(birth_df)
# colSums(is.na(birth_df)) 
```

Using existing literature, I took a knowledge-based approach to developing my model. 

- gender of newborn, race of mother, age of mother,


```{r}

```

