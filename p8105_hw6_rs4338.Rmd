---
title: "p8105_hw6_rs4338"
author: "Rebecca Shyu"
date: "2024-11-20"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(haven)
library(kableExtra)
library(leaflet)
library(p8105.datasets)
library(broom)
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
	dpi=300
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
## Problem 0:

* Create a public GitHub repo + local R Project: p8105_hw6_rs4338
* Create a single .Rmd file named p8105_hw6_rs4338.Rmd that renders to github_document
* Create a subdirectory (data) to store the local data files, and use relative paths to access these data files
* Submit a link to your repo via Courseworks: https://github.com/rysgpd/p8105_hw6_rs4338

## Problem 1:

* Plot the distribution of your estimates, and describe these in words. 
* Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r2 and log(b0 * b1)
```{r prob1_import, message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```
```{r prob1_pt1}
prob1_function1 = function(input_df) {
  input_df = as.data.frame(input_df)
  fit = lm(tmax ~ tmin, data = input_df)
  
  return(
    fit %>% 
      broom::glance() %>% 
      select(r.squared)
  )
}

# r^2 function and results
prob1_results1 = 
  weather_df %>% 
  modelr::bootstrap(5000) %>% 
  mutate(
    lm_test = map(strap, prob1_function1)
  ) %>% 
  unnest(lm_test)

prob1_results1 %>% 
  ggplot(aes(x=r.squared)) + 
  geom_density() +
  labs(
    title = "Bootstrapped Samples for R^2 for Predicting Tmax using Tmin",
    x = "R Squared Values",
    y = "Density"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

``` 


* For r^2, the 95% confidence interval is `r prob1_results1 %>% pull(r.squared) %>% quantile(0.025)` to `r prob1_results1 %>% pull(r.squared) %>% quantile(0.975)`. 
* The distribution is pretty symmetrical with the r^2 values on the higher side which is a good indication of the regression model fitting the data well.

```{r prob1_pt2}

# log(b0 * b1) function and results

prob1_function2 = function(input_df) {
  input_df = as.data.frame(input_df)
  fit = lm(tmax ~ tmin, data = input_df)
  
  return(
    fit %>% 
      broom::tidy() %>% 
      select(term, estimate) %>% 
      pivot_wider(
        names_from = term,
        values_from = estimate) %>% 
      rename(intercept = 1)
  )
}

prob1_results2 = 
  weather_df %>% 
  modelr::bootstrap(5000) %>% 
  mutate(
    lm_test = map(strap, prob1_function2)
  ) %>% 
  unnest(lm_test) %>% 
  mutate(
    log_value = log(intercept * tmin)
  )

prob1_results2%>% 
  ggplot(aes(x=log_value)) + 
  geom_density() +
  labs(
    title = "Bootstrapped Samples for Log(B0 * B1) for Predicting Tmax using Tmin",
    x = "Log Values",
    y = "Density"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

* For the log value, the 95% confidence interval is `r prob1_results2 %>% pull(log_value) %>% quantile(0.025)` to `r prob1_results2 %>% pull(log_value) %>% quantile(0.975)`. 
* This one is less symmetrical, which indicates a potential skewed distribution or nonlinear relationships. Bootstrapping can help get these estimates and distributions, to make sure they aren't just outliers that makes it not symmetrical.

## Problem 2:

```{r prob2_setup}

homicide_df = read_csv("data/homicide-data.csv", na = c("", "Unknown"),
                       col_types = cols(
                         victim_sex = col_factor(levels = c("Female", "Male")),
                         victim_race = col_factor(),
                         disposition = col_factor()
                       )) %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = paste(city, state, sep = ", "),
    city_state = as.factor(city_state),
    reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"),
    solved = if_else(disposition == "Closed by arrest", 1, 0)
  ) %>% 
  filter(
    !(city_state == "Dallas, TX" | city_state == "Phoenix, AZ" | city_state == "Kansas City, MO" | city_state == "Tulsa, AL"),
    (victim_race == "White" | victim_race == "Black")
  )
```

* For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors

```{r prob2_baltimore}
balt_df = homicide_df %>% 
  filter(city_state == "Baltimore, MD")

fit = glm(solved ~ victim_age + victim_sex + victim_race, data = balt_df)

fit %>% 
  broom::tidy(conf.int=TRUE, exponentiate = TRUE) %>% 
  filter(
    term == "victim_sexMale"
  ) %>% 
  knitr::kable(caption = "Baltimore Sample Results")
```

* Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 
* Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.
  * The plot shows that there is a larger discrepancy between solved homicides when considering gender of the victim. In Albuquerque, the odds ratio is greater than 1 which means cases for male victims are about 16% more likely to be solved for male victims. In the majority of other cities, the odds ratio is less than 1, so cases for female victims in these cities are more likely to be solved. NYC is very skewed to under 0.8, which means over 20% more likely. Also, many of the confidence intervals don't even contain 1, which shows a disparity either way.


```{r prob2_function, fig.width=10}
prob2_function = function(input_df) {
  fit = glm(solved ~ victim_age + victim_sex + victim_race, data = input_df)

  return(
    fit %>% 
      broom::tidy(conf.int=TRUE, exponentiate = TRUE) %>% 
      filter(
        term == "victim_sexMale"
      ) %>% 
      select(estimate, conf.low, conf.high)
  )
}

homicide_result = 
  homicide_df %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(
    glm_tests = map(data, prob2_function)
  ) %>% 
  unnest(glm_tests) 

homicide_result %>% 
  ungroup() %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) %>% 
  ggplot(aes(y = city_state, x=estimate)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high))+
  labs(
    title = "Odds Ratio of Solving Homicides - Comparing Male and Female Victims",
    x = "Odds Ratio",
    y = "Location"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )


```

## Problem 3:

* Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r prob3_setup}

birth_df = read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(ifelse(babysex == 1, "Male", "Female")),
    frace = as.factor(recode(frace,
                   `1` = "White",
                   `2` = "Black",
                   `3` = "Asian",
                   `4` = "Puerto Rican",
                   `8` = "Other",
                   `9` = "Unknown")),
    malform = as.factor(malform),
    mrace = as.factor(recode(mrace,
                   `1` = "White",
                   `2` = "Black",
                   `3` = "Asian",
                   `4` = "Puerto Rican",
                   `8` = "Other"))
    )

#check for missing data/general checks
# summary(birth_df)
# colSums(is.na(birth_df)) 
```

* Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.
  * Using existing literature, I took a knowledge-based approach to developing my model. I propose that the regression model for birthweight is based on the following factors gender of newborn (`babysex`), race of mother (`mrace`), age of mother (`momage`), previous births (`parity`), maternal height (`mheight`), pre-pregnancy weight (`ppwt`), weight gain during pregnancy (`wtgain`), and smoking (`smoken`). I also put in `gaweeks` because that seems self explanatory to me to include in my model. I did not include any interaction factors at this point in my analysis.
  * Citations:
    * Dola SS, Valderrama CE. Exploring parental factors influencing low birth weight on the 2022 CDC natality dataset. BMC Med Inform Decis Mak. 2024;24(1):367. Published 2024 Nov 30. doi:10.1186/s12911-024-02783-x
    * Moreira AIM, Sousa PRM, Sarno F. Low birth weight and its associated factors. Einstein (Sao Paulo). 2018;16(4):eAO4251. Published 2018 Nov 8. doi:10.31744/einstein_journal/2018AO4251
    * Falcão, IR, Ribeiro-Silva, R, de Almeida, MF, et al. Factors associated with low birth weight at term: a population-based linkage study of the 100 million Brazilian cohort. BMC Pregnancy Childbirth 20, 536 (2020). https://doi.org/10.1186/s12884-020-03226-x


```{r prob3_mymodel}

prob3_lm_fit = lm(bwt ~ babysex + mrace + momage + parity + mheight + ppwt + wtgain + smoken + gaweeks, data = birth_df)

prob3_lm_fit %>%
  broom::tidy() %>% 
  knitr::kable()

birth_df %>% 
  add_residuals(prob3_lm_fit) %>% 
  add_predictions(prob3_lm_fit) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(
    title = "Predicted vs Residuals for My Linear Regression Model",
    x = "Predicted",
    y = "Residuals"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```

* This plot seems to be concentrated around residual 0 and predicted value of 3000, which may indicate that my model is not perfect and may be overfitting on certain variables, but it's a decent model. There are also many dots that have very large residuals (over 1000), which is not great in terms of fit. 


* Compare your model to two others:
  * One using length at birth and gestational age as predictors (main effects only)
  * One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
  
```{r prob3_cv, warning=FALSE}

# similar code from class

# mymodel = my proposed model from the part above
# model1 = the one using length at birth and gestational age as predictors
# model2 = the one using head circumference, length, sex, and all interactions (including the three-way interaction)

cv_df = 
  crossv_mc(birth_df, 100) %>% 
  mutate(
    mymodel = map(train, \(df) lm(bwt ~ babysex + mrace + momage + parity + mheight + ppwt + wtgain + smoken + gaweeks, data = df)),
    model1 = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model2 = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))) %>% 
  mutate(
    rmse_mymodel = map2_dbl(mymodel, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model1 = map2_dbl(model1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model2 = map2_dbl(model2, test, \(mod, df) rmse(model = mod, data = df)))

cv_df %>% 
  select(
    starts_with("rmse")
  ) %>% 
  pivot_longer(
    cols = everything(),
    names_to = "model_type",
    values_to = "rmse_values",
    names_prefix = "rmse_"
  ) %>% 
  mutate(model_type = fct_inorder(model_type)) |> 
  ggplot(aes(x = model_type, y = rmse_values)) + geom_violin() +
  labs(
    title = "RSMEs Across Models",
    x = "Model Type",
    y = "RMSE Values"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

* As expected, my model was not good at all, which makes sense because it would be too simple to include many variables and assume a perfect linear regression without any interactions. Model 1 is the very simple one (main effects only) which made it a little better (smaller RMSE values), and model 2 was the interactions one which did the best. Model2 can be improved include more factors/interactions but it's the best out of the 3 at this point. 
